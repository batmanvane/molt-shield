{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molt-Shield LLM Demo\n",
    "\n",
    "**Real-world example** - This notebook demonstrates a complete workflow where:\n",
    "1. Proprietary simulation data is sanitized\n",
    "2. An LLM analyzes the sanitized data\n",
    "3. LLM suggestions are rehydrated back to original values\n",
    "\n",
    "This uses a simulated LLM response (since free API keys require personal accounts), but shows the exact workflow you'd use with Claude, GPT, or Gemini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q lxml pydantic pyyaml requests\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/molt-shield/src')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/molt-shield')\n",
    "\n",
    "from src.config import load_config, MaskingConfig, ShufflingConfig\n",
    "from src.gatekeeper import apply_gatekeeper, mask_values, shuffle_siblings, DEFAULT_TAG_MAP, _apply_tag_shadowing\n",
    "from src.policy_engine import Policy, Rule\n",
    "from src.vault import Vault\n",
    "from pathlib import Path\n",
    "from lxml import etree\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your Proprietary Data\n",
    "\n",
    "Imagine this is a proprietary turbine blade simulation - highly valuable IP that you don't want to leak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proprietary turbine blade simulation data\n",
    "PROPRIETARY_XML = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<turbine_simulation>\n",
    "    <metadata>\n",
    "        <project>CFD-2024-TURBINE-ALPHA</project>\n",
    "        <engineer>Dr. Smith</engineer>\n",
    "    </metadata>\n",
    "    <blade id=\"blade_001\">\n",
    "        <material>Inconel718</material>\n",
    "        <stress_mpa>850.5</stress_mpa>\n",
    "        <temperature_celsius>650.0</temperature_celsius>\n",
    "        <efficiency>0.92</efficiency>\n",
    "        <lifespan_hours>25000</lifespan_hours>\n",
    "    </blade>\n",
    "    <blade id=\"blade_002\">\n",
    "        <material>Inconel718</material>\n",
    "        <stress_mpa>920.3</stress_mpa>\n",
    "        <temperature_celsius>680.5</temperature_celsius>\n",
    "        <efficiency>0.89</efficiency>\n",
    "        <lifespan_hours>18000</lifespan_hours>\n",
    "    </blade>\n",
    "    <blade id=\"blade_003\">\n",
    "        <material>Ti6Al4V</material>\n",
    "        <stress_mpa>780.0</stress_mpa>\n",
    "        <temperature_celsius>520.0</temperature_celsius>\n",
    "        <efficiency>0.94</efficiency>\n",
    "        <lifespan_hours>35000</lifespan_hours>\n",
    "    </blade>\n",
    "</turbine_simulation>\"\"\"\n",
    "\n",
    "# Save original\n",
    "with open('turbine_data.xml', 'w') as f:\n",
    "    f.write(PROPRIETARY_XML)\n",
    "\n",
    "print(\"=== YOUR PROPRIETARY DATA (NEVER SHARE THIS!) ===\")\n",
    "print(PROPRIETARY_XML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sanitize with Molt-Shield\n",
    "\n",
    "Now let's sanitize this data so it can be safely shared with an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the policy\n",
    "masking_config = MaskingConfig()\n",
    "shuffling_config = ShufflingConfig(seed=42)\n",
    "\n",
    "# Parse and mask\n",
    "xml_tree = etree.fromstring(PROPRIETARY_XML.encode())\n",
    "vault = Vault('turbine_vault.json')\n",
    "\n",
    "# Step 1: Mask numeric values\n",
    "masked_tree = mask_values(xml_tree, masking_config, vault)\n",
    "\n",
    "# Step 2: Shadow tag names\n",
    "# Extend the default map for turbine-specific tags\n",
    "TURBINE_TAG_MAP = {**DEFAULT_TAG_MAP, {\n",
    "    \"stress_mpa\": \"stress_metric\",\n",
    "    \"temperature_celsius\": \"thermal_reading\",\n",
    "    \"efficiency\": \"performance_factor\",\n",
    "    \"lifespan_hours\": \"operational_duration\",\n",
    "    \"material\": \"alloy_type\",\n",
    "}}\n",
    "\n",
    "_apply_tag_shadowing(masked_tree, TURBINE_TAG_MAP)\n",
    "shadowed_xml = etree.tostring(masked_tree, encoding='unicode')\n",
    "\n",
    "# Step 3: Shuffle siblings (optional - for demo we skip this)\n",
    "sanitized_xml = shadowed_xml\n",
    "\n",
    "# Save vault for later rehydration\n",
    "vault.save()\n",
    "\n",
    "print(\"=== SANITIZED DATA (SAFE TO SHARE WITH LLM) ===\")\n",
    "print(sanitized_xml)\n",
    "print(f\"\\nVault saved with {len(vault)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulated LLM Response\n",
    "\n",
    "This is what an LLM like Claude, GPT, or Gemini would return when given the sanitized data.\n",
    "\n",
    "The LLM sees ONLY the sanitized data and makes suggestions using the masked values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated LLM response (in real usage, you'd call an API)\n",
    "LLM_RESPONSE = \"\"\"\n",
    "Based on the sanitized turbine blade data, here are my optimization suggestions:\n",
    "\n",
    "**Analysis:**\n",
    "- blade_001 has moderate stress (VAL_xxx1) and good efficiency (VAL_xxx2)\n",
    "- blade_002 shows high stress (VAL_xxx3) which is concerning\n",
    "- blade_003 has the best efficiency but moderate thermal readings\n",
    "\n",
    "**Recommendations:**\n",
    "1. For blade_002: Reduce stress_metric below VAL_xxx1 by 15%\n",
    "2. Consider material change for blade_002 to match blade_003 alloy_type\n",
    "3. Target operational_duration > 20000 hours - blade_002 needs improvement\n",
    "\n",
    "**Specific changes suggested:**\n",
    "- stress_mpa: VAL_xxx3 → 750.0 (reduce from current high)\n",
    "- thermal_reading: VAL_xxx4 → 600.0 (lower for longevity)\n",
    "- performance_factor: VAL_xxx5 → 0.91 (optimize)\n",
    "\"\"\"\n",
    "\n",
    "# In JSON format (as you'd get from an LLM API)\n",
    "LLM_SUGGESTIONS = {\n",
    "    \"blade_002\": {\n",
    "        \"stress_metric\": \"VAL_xxx1\",  # LLM uses masked value reference\n",
    "        \"thermal_reading\": \"VAL_xxx4\",\n",
    "        \"performance_factor\": \"VAL_xxx5\",\n",
    "        \"alloy_type\": \"Ti6Al4V\"  # This wasn't masked, LLM can see it\n",
    "    },\n",
    "    \"recommendations\": [\n",
    "        \"reduce stress by 15%\",\n",
    "        \"increase operational_duration above 20000\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== LLM RESPONSE (USING MASKED VALUES) ===\")\n",
    "print(LLM_RESPONSE)\n",
    "print(\"\\n=== LLM SUGGESTIONS (JSON) ===\")\n",
    "print(json.dumps(LLM_SUGGESTIONS, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rehydration\n",
    "\n",
    "Now we map the LLM's suggestions back to original values using the vault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vault\n",
    "vault = Vault('turbine_vault.json')\n",
    "vault.load()\n",
    "\n",
    "# Rehydrate the suggestions\n",
    "print(\"=== REHYDRATION ===\\n\")\n",
    "\n",
    "# Find a masked value from our vault\n",
    "sample_masked = list(vault.entries.keys())[0]\n",
    "sample_original = vault.restore(sample_masked)\n",
    "\n",
    "print(f\"Example mapping:\")\n",
    "print(f\"  LLM sees: {sample_masked}\")\n",
    "print(f\"  Actually means: {sample_original}\")\n",
    "\n",
    "# Rehydrate the JSON suggestions\n",
    "rehydrated_suggestions = vault.rehydrate_dict(LLM_SUGGESTIONS)\n",
    "\n",
    "print(\"\\n=== REHYDRATED SUGGESTIONS (BACK TO ORIGINAL VALUES) ===\")\n",
    "print(json.dumps(rehydrated_suggestions, indent=2))\n",
    "\n",
    "# Rehydrate text response (for demonstration)\n",
    "rehydrated_text = vault.rehydrate_xml(LLM_RESPONSE)\n",
    "print(\"\\n=== SAMPLE OF REHYDRATED TEXT ===\")\n",
    "# Show just a portion\n",
    "import re\n",
    "matches = re.findall(r'VAL_[a-z0-9]+', rehydrated_text)\n",
    "for m in set(matches)[:3]:\n",
    "    original = vault.restore(m)\n",
    "    print(f\"  {m} → {original}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete Workflow\n",
    "\n",
    "Here's the full pipeline in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline using apply_gatekeeper\n",
    "policy = Policy(\n",
    "    version=\"1.0\",\n",
    "    global_masking=True,\n",
    "    rules=[\n",
    "        Rule(tag_pattern=\"stress_mpa\", action=\"mask_value\"),\n",
    "        Rule(tag_pattern=\"temperature_celsius\", action=\"mask_value\"),\n",
    "        Rule(tag_pattern=\"efficiency\", action=\"mask_value\"),\n",
    "        Rule(tag_pattern=\"lifespan_hours\", action=\"mask_value\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = load_config('config/default.yaml')\n",
    "sanitized_path, vault_path = apply_gatekeeper(Path('turbine_data.xml'), policy, config)\n",
    "\n",
    "print(\"=== COMPLETE PIPELINE ===\\n\")\n",
    "print(f\"Input: turbine_data.xml\")\n",
    "print(f\"Sanitized output: {sanitized_path}\")\n",
    "print(f\"Vault: {vault_path}\")\n",
    "\n",
    "print(\"\\n--- SANITIZED CONTENT ---\")\n",
    "print(sanitized_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with Real LLM APIs\n",
    "\n",
    "To use with a real LLM, you would:\n",
    "\n",
    "### Option 1: Claude Desktop (MCP)\n",
    "```python\n",
    "# Configure in Claude Desktop settings:\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"molt-shield\": {\n",
    "      \"command\": \"python\",\n",
    "      \"args\": [\"-m\", \"src.server\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Option 2: OpenAI API\n",
    "```python\n",
    "import openai\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze this sanitized data: {sanitized_xml}\"}\n",
    "    ]\n",
    ")\n",
    "# Then rehydrate the response using vault\n",
    "```\n",
    "\n",
    "### Option 3: Gemini API\n",
    "```python\n",
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(f\"Analyze: {sanitized_xml}\")\n",
    "# Then rehydrate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Molt-Shield workflow:\n",
    "\n",
    "```\n",
    "1. YOUR DATA → 2. SANITIZE → 3. LLM → 4. REHYDRATE → 5. ORIGINAL\n",
    "   (private)      (safe to share)   (analyzes)    (maps back)\n",
    "```\n",
    "\n",
    "This ensures your proprietary data never leaves your control in an identifiable form."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
