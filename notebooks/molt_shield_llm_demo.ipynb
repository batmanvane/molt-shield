{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdGz4VjlFnm0"
      },
      "source": [
        "# Molt-Shield LLM Demo\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/batmanvane/molt-shield/blob/main/notebooks/molt_shield_llm_demo.ipynb)\n",
        "\n",
        "**Real-world example** - This notebook demonstrates a complete workflow where:\n",
        "1. Proprietary simulation data is sanitized\n",
        "2. An LLM analyzes the sanitized data\n",
        "3. LLM suggestions are rehydrated back to original values\n",
        "\n",
        "This uses a simulated LLM response (since free API keys require personal accounts), but shows the exact workflow you'd use with Claude, GPT, or Gemini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4e58sH6Fnm2"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "First, mount this notebook from GitHub or upload the files, then install dependencies.\n",
        "\n",
        "### Option A: Clone from GitHub (recommended)\n",
        "```python\n",
        "!git clone https://github.com/batmanvane/molt-shield.git /content/molt-shield\n",
        "```\n",
        "\n",
        "### Option B: Upload files manually\n",
        "Upload these files to Colab:\n",
        "- `src/` folder\n",
        "- `config/` folder\n",
        "\n",
        "### Option C: Install dependencies only\n",
        "```python\n",
        "!pip install -q lxml pydantic pyyaml requests\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-g3WU1PhFnm2",
        "outputId": "210af5e8-5824-44c9-e49d-9011a93987f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Dependencies installed: lxml, pydantic, pyyaml, requests\n",
            "fatal: destination path '/content/molt-shield' already exists and is not an empty directory.\n",
            "✓ Environment ready!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SETUP: Install dependencies (run this FIRST)\n",
        "# ============================================================\n",
        "# These packages are NOT pre-installed in Google Colab\n",
        "\n",
        "!pip install -q lxml pydantic pyyaml requests\n",
        "\n",
        "print(\"✓ Dependencies installed: lxml, pydantic, pyyaml, requests\")\n",
        "\n",
        "# Clone repository\n",
        "!git clone https://github.com/batmanvane/molt-shield.git /content/molt-shield\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '/content/molt-shield/src')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/molt-shield')\n",
        "\n",
        "# Import Molt-Shield modules\n",
        "from src.config import load_config, MaskingConfig, ShufflingConfig\n",
        "from src.gatekeeper import apply_gatekeeper, mask_values, _apply_tag_shadowing, DEFAULT_TAG_MAP\n",
        "from src.policy_engine import Policy, Rule\n",
        "from src.vault import Vault\n",
        "from pathlib import Path\n",
        "from lxml import etree\n",
        "import json\n",
        "\n",
        "print(\"✓ Environment ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Pp9UvVFnm3"
      },
      "source": [
        "## 2. Your Proprietary Data\n",
        "\n",
        "Imagine this is a proprietary turbine blade simulation - highly valuable IP that you don't want to leak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uAKXt0ClFnm3",
        "outputId": "2a547b76-7996-49c6-9ddc-34686572394f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== YOUR PROPRIETARY DATA (NEVER SHARE THIS!) ===\n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<turbine_simulation>\n",
            "    <metadata>\n",
            "        <project>CFD-2024-TURBINE-ALPHA</project>\n",
            "        <engineer>Dr. Smith</engineer>\n",
            "    </metadata>\n",
            "    <blade id=\"blade_001\">\n",
            "        <material>Inconel718</material>\n",
            "        <stress_mpa>850.5</stress_mpa>\n",
            "        <temperature_celsius>650.0</temperature_celsius>\n",
            "        <efficiency>0.92</efficiency>\n",
            "        <lifespan_hours>25000</lifespan_hours>\n",
            "    </blade>\n",
            "    <blade id=\"blade_002\">\n",
            "        <material>Inconel718</material>\n",
            "        <stress_mpa>920.3</stress_mpa>\n",
            "        <temperature_celsius>680.5</temperature_celsius>\n",
            "        <efficiency>0.89</efficiency>\n",
            "        <lifespan_hours>18000</lifespan_hours>\n",
            "    </blade>\n",
            "    <blade id=\"blade_003\">\n",
            "        <material>Ti6Al4V</material>\n",
            "        <stress_mpa>780.0</stress_mpa>\n",
            "        <temperature_celsius>520.0</temperature_celsius>\n",
            "        <efficiency>0.94</efficiency>\n",
            "        <lifespan_hours>35000</lifespan_hours>\n",
            "    </blade>\n",
            "</turbine_simulation>\n"
          ]
        }
      ],
      "source": [
        "# Proprietary turbine blade simulation data\n",
        "PROPRIETARY_XML = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "<turbine_simulation>\n",
        "    <metadata>\n",
        "        <project>CFD-2024-TURBINE-ALPHA</project>\n",
        "        <engineer>Dr. Smith</engineer>\n",
        "    </metadata>\n",
        "    <blade id=\"blade_001\">\n",
        "        <material>Inconel718</material>\n",
        "        <stress_mpa>850.5</stress_mpa>\n",
        "        <temperature_celsius>650.0</temperature_celsius>\n",
        "        <efficiency>0.92</efficiency>\n",
        "        <lifespan_hours>25000</lifespan_hours>\n",
        "    </blade>\n",
        "    <blade id=\"blade_002\">\n",
        "        <material>Inconel718</material>\n",
        "        <stress_mpa>920.3</stress_mpa>\n",
        "        <temperature_celsius>680.5</temperature_celsius>\n",
        "        <efficiency>0.89</efficiency>\n",
        "        <lifespan_hours>18000</lifespan_hours>\n",
        "    </blade>\n",
        "    <blade id=\"blade_003\">\n",
        "        <material>Ti6Al4V</material>\n",
        "        <stress_mpa>780.0</stress_mpa>\n",
        "        <temperature_celsius>520.0</temperature_celsius>\n",
        "        <efficiency>0.94</efficiency>\n",
        "        <lifespan_hours>35000</lifespan_hours>\n",
        "    </blade>\n",
        "</turbine_simulation>\"\"\"\n",
        "\n",
        "# Save original\n",
        "with open('turbine_data.xml', 'w') as f:\n",
        "    f.write(PROPRIETARY_XML)\n",
        "\n",
        "print(\"=== YOUR PROPRIETARY DATA (NEVER SHARE THIS!) ===\")\n",
        "print(PROPRIETARY_XML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtRwqfu2Fnm3"
      },
      "source": [
        "## 3. Sanitize with Molt-Shield\n",
        "\n",
        "Now let's sanitize this data so it can be safely shared with an LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6g_j3nxUFnm3",
        "outputId": "689e3bf5-f5c9-46d1-8543-00fb1bc34181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SANITIZED DATA (SAFE TO SHARE WITH LLM) ===\n",
            "<turbine_simulation>\n",
            "    <metadata>\n",
            "        <project>CFD-2024-TURBINE-ALPHA</project>\n",
            "        <engineer>Dr. Smith</engineer>\n",
            "    </metadata>\n",
            "    <blade id=\"blade_001\">\n",
            "        <alloy_type>Inconel718</alloy_type>\n",
            "        <stress_metric>VAL_c301803539b8</stress_metric>\n",
            "        <thermal_reading>VAL_ac7a925dd779</thermal_reading>\n",
            "        <performance_factor>VAL_8a417ebdaf37</performance_factor>\n",
            "        <operational_duration>VAL_ace86cac1764</operational_duration>\n",
            "    </blade>\n",
            "    <blade id=\"blade_002\">\n",
            "        <alloy_type>Inconel718</alloy_type>\n",
            "        <stress_metric>VAL_194aa257aa28</stress_metric>\n",
            "        <thermal_reading>VAL_3501e91d9153</thermal_reading>\n",
            "        <performance_factor>VAL_05516f818ac7</performance_factor>\n",
            "        <operational_duration>VAL_7ced2306ef9f</operational_duration>\n",
            "    </blade>\n",
            "    <blade id=\"blade_003\">\n",
            "        <alloy_type>Ti6Al4V</alloy_type>\n",
            "        <stress_metric>VAL_ee1f184a8a5a</stress_metric>\n",
            "        <thermal_reading>VAL_30da69699257</thermal_reading>\n",
            "        <performance_factor>VAL_de128ac5f9ca</performance_factor>\n",
            "        <operational_duration>VAL_c278c53dc4e5</operational_duration>\n",
            "    </blade>\n",
            "</turbine_simulation>\n",
            "\n",
            "Vault saved with 12 entries\n"
          ]
        }
      ],
      "source": [
        "# Configure the policy\n",
        "masking_config = MaskingConfig()\n",
        "shuffling_config = ShufflingConfig(seed=42)\n",
        "\n",
        "# Parse and mask\n",
        "xml_tree = etree.fromstring(PROPRIETARY_XML.encode())\n",
        "vault = Vault('turbine_vault.json')\n",
        "\n",
        "# Step 1: Mask numeric values\n",
        "masked_tree = mask_values(xml_tree, masking_config, vault)\n",
        "\n",
        "# Step 2: Shadow tag names\n",
        "# Extend the default map for turbine-specific tags\n",
        "TURBINE_TAG_MAP = {**DEFAULT_TAG_MAP,\n",
        "    \"stress_mpa\": \"stress_metric\",\n",
        "    \"temperature_celsius\": \"thermal_reading\",\n",
        "    \"efficiency\": \"performance_factor\",\n",
        "    \"lifespan_hours\": \"operational_duration\",\n",
        "    \"material\": \"alloy_type\",\n",
        "}\n",
        "\n",
        "_apply_tag_shadowing(masked_tree, TURBINE_TAG_MAP)\n",
        "shadowed_xml = etree.tostring(masked_tree, encoding='unicode')\n",
        "\n",
        "# Step 3: Shuffle siblings (optional - for demo we skip this)\n",
        "sanitized_xml = shadowed_xml\n",
        "\n",
        "# Save vault for later rehydration\n",
        "vault.save()\n",
        "\n",
        "print(\"=== SANITIZED DATA (SAFE TO SHARE WITH LLM) ===\")\n",
        "print(sanitized_xml)\n",
        "print(f\"\\nVault saved with {len(vault)} entries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekw2q4miFnm3"
      },
      "source": [
        "## 4. Simulated LLM Response\n",
        "\n",
        "This is what an LLM like Claude, GPT, or Gemini would return when given the sanitized data.\n",
        "\n",
        "The LLM sees ONLY the sanitized data and makes suggestions using the masked values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8QbWfA19Fnm4",
        "outputId": "2e9e0664-5e16-4f55-9e7f-09e3be445ea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== LLM RESPONSE (USING MASKED VALUES) ===\n",
            "\n",
            "Based on the sanitized turbine blade data, here are my optimization suggestions:\n",
            "\n",
            "**Analysis:**\n",
            "- blade_001 has moderate stress (VAL_xxx1) and good efficiency (VAL_xxx2)\n",
            "- blade_002 shows high stress (VAL_xxx3) which is concerning\n",
            "- blade_003 has the best efficiency but moderate thermal readings\n",
            "\n",
            "**Recommendations:**\n",
            "1. For blade_002: Reduce stress_metric below VAL_xxx1 by 15%\n",
            "2. Consider material change for blade_002 to match blade_003 alloy_type\n",
            "3. Target operational_duration > 20000 hours - blade_002 needs improvement\n",
            "\n",
            "**Specific changes suggested:**\n",
            "- stress_mpa: VAL_xxx3 → 750.0 (reduce from current high)\n",
            "- thermal_reading: VAL_xxx4 → 600.0 (lower for longevity)\n",
            "- performance_factor: VAL_xxx5 → 0.91 (optimize)\n",
            "\n",
            "\n",
            "=== LLM SUGGESTIONS (JSON) ===\n",
            "{\n",
            "  \"blade_002\": {\n",
            "    \"stress_metric\": \"VAL_xxx1\",\n",
            "    \"thermal_reading\": \"VAL_xxx4\",\n",
            "    \"performance_factor\": \"VAL_xxx5\",\n",
            "    \"alloy_type\": \"Ti6Al4V\"\n",
            "  },\n",
            "  \"recommendations\": [\n",
            "    \"reduce stress by 15%\",\n",
            "    \"increase operational_duration above 20000\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Simulated LLM response (in real usage, you'd call an API)\n",
        "LLM_RESPONSE = \"\"\"\n",
        "Based on the sanitized turbine blade data, here are my optimization suggestions:\n",
        "\n",
        "**Analysis:**\n",
        "- blade_001 has moderate stress (VAL_xxx1) and good efficiency (VAL_xxx2)\n",
        "- blade_002 shows high stress (VAL_xxx3) which is concerning\n",
        "- blade_003 has the best efficiency but moderate thermal readings\n",
        "\n",
        "**Recommendations:**\n",
        "1. For blade_002: Reduce stress_metric below VAL_xxx1 by 15%\n",
        "2. Consider material change for blade_002 to match blade_003 alloy_type\n",
        "3. Target operational_duration > 20000 hours - blade_002 needs improvement\n",
        "\n",
        "**Specific changes suggested:**\n",
        "- stress_mpa: VAL_xxx3 → 750.0 (reduce from current high)\n",
        "- thermal_reading: VAL_xxx4 → 600.0 (lower for longevity)\n",
        "- performance_factor: VAL_xxx5 → 0.91 (optimize)\n",
        "\"\"\"\n",
        "\n",
        "# In JSON format (as you'd get from an LLM API)\n",
        "LLM_SUGGESTIONS = {\n",
        "    \"blade_002\": {\n",
        "        \"stress_metric\": \"VAL_xxx1\",  # LLM uses masked value reference\n",
        "        \"thermal_reading\": \"VAL_xxx4\",\n",
        "        \"performance_factor\": \"VAL_xxx5\",\n",
        "        \"alloy_type\": \"Ti6Al4V\"  # This wasn't masked, LLM can see it\n",
        "    },\n",
        "    \"recommendations\": [\n",
        "        \"reduce stress by 15%\",\n",
        "        \"increase operational_duration above 20000\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"=== LLM RESPONSE (USING MASKED VALUES) ===\")\n",
        "print(LLM_RESPONSE)\n",
        "print(\"\\n=== LLM SUGGESTIONS (JSON) ===\")\n",
        "print(json.dumps(LLM_SUGGESTIONS, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P16RufBRFnm4"
      },
      "source": [
        "## 5. Rehydration\n",
        "\n",
        "Now we map the LLM's suggestions back to original values using the vault."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iG_rNn71Fnm4",
        "outputId": "4b80fe6f-e03f-47a1-d46e-1229d4ec84a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== REHYDRATION ===\n",
            "\n",
            "Example mapping:\n",
            "  LLM sees: VAL_c301803539b8\n",
            "  Actually means: 850.5\n",
            "\n",
            "=== REHYDRATED SUGGESTIONS (BACK TO ORIGINAL VALUES) ===\n",
            "{\n",
            "  \"blade_002\": {\n",
            "    \"stress_metric\": \"VAL_xxx1\",\n",
            "    \"thermal_reading\": \"VAL_xxx4\",\n",
            "    \"performance_factor\": \"VAL_xxx5\",\n",
            "    \"alloy_type\": \"Ti6Al4V\"\n",
            "  },\n",
            "  \"recommendations\": [\n",
            "    \"reduce stress by 15%\",\n",
            "    \"increase operational_duration above 20000\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== SAMPLE OF REHYDRATED TEXT ===\n",
            "  VAL_xxx5 → None\n",
            "  VAL_xxx3 → None\n",
            "  VAL_xxx4 → None\n"
          ]
        }
      ],
      "source": [
        "# Load the vault\n",
        "vault = Vault('turbine_vault.json')\n",
        "vault.load()\n",
        "\n",
        "# Rehydrate the suggestions\n",
        "print(\"=== REHYDRATION ===\\n\")\n",
        "\n",
        "# Find a masked value from our vault\n",
        "sample_masked = list(vault.entries.keys())[0]\n",
        "sample_original = vault.restore(sample_masked)\n",
        "\n",
        "print(f\"Example mapping:\")\n",
        "print(f\"  LLM sees: {sample_masked}\")\n",
        "print(f\"  Actually means: {sample_original}\")\n",
        "\n",
        "# Rehydrate the JSON suggestions\n",
        "rehydrated_suggestions = vault.rehydrate_dict(LLM_SUGGESTIONS)\n",
        "\n",
        "print(\"\\n=== REHYDRATED SUGGESTIONS (BACK TO ORIGINAL VALUES) ===\")\n",
        "print(json.dumps(rehydrated_suggestions, indent=2))\n",
        "\n",
        "# Rehydrate text response (for demonstration)\n",
        "rehydrated_text = vault.rehydrate_xml(LLM_RESPONSE)\n",
        "print(\"\\n=== SAMPLE OF REHYDRATED TEXT ===\")\n",
        "# Show just a portion\n",
        "import re\n",
        "matches = re.findall(r'VAL_[a-z0-9]+', rehydrated_text)\n",
        "for m in list(set(matches))[:3]:\n",
        "    original = vault.restore(m)\n",
        "    print(f\"  {m} → {original}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Rqb-O1Fnm4"
      },
      "source": [
        "## 6. Complete Workflow\n",
        "\n",
        "Here's the full pipeline in practice:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mKROJWXeFnm4",
        "outputId": "0e37b476-3911-4f2a-f6ff-6bfadcf448b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== COMPLETE PIPELINE ===\n",
            "\n",
            "Input: turbine_data.xml\n",
            "Sanitized output: turbine_data_sanitized.xml\n",
            "Vault: session_vault.json\n",
            "\n",
            "--- SANITIZED CONTENT ---\n",
            "<?xml version='1.0' encoding='UTF-8'?>\n",
            "<turbine_simulation>\n",
            "    <metadata>\n",
            "        <project>CFD-2024-TURBINE-ALPHA</project>\n",
            "        <engineer>Dr. Smith</engineer>\n",
            "    </metadata>\n",
            "    <blade id=\"blade_001\">\n",
            "        <material>Inconel718</material>\n",
            "        <stress_mpa>VAL_0536288773fa</stress_mpa>\n",
            "        <temperature_celsius>VAL_ce0d296139e8</temperature_celsius>\n",
            "        <efficiency>VAL_ae0a2f21b4c1</efficiency>\n",
            "        <lifespan_hours>VAL_96225e1d98e9</lifespan_hours>\n",
            "    </blade>\n",
            "    <blade id=\"blade_002\">\n",
            "        <material>Inconel718</material>\n",
            "        <stress_mpa>VAL_f56979641a2d</stress_mpa>\n",
            "        <temperature_celsius>VAL_26981f392b6b</temperature_celsius>\n",
            "        <efficiency>VAL_d7502442358d</efficiency>\n",
            "        <lifespan_hours>VAL_74cb13a7fdd8</lifespan_hours>\n",
            "    </blade>\n",
            "    <blade id=\"blade_003\">\n",
            "        <material>Ti6Al4V</material>\n",
            "        <stress_mpa>VAL_3d5a12355a82</stress_mpa>\n",
            "        <temperature_celsius>VAL_6ad21c8ca828</temperature_celsius>\n",
            "        <efficiency>VAL_234574bf5513</efficiency>\n",
            "        <lifespan_hours>VAL_34305c078f83</lifespan_hours>\n",
            "    </blade>\n",
            "</turbine_simulation>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Full pipeline using apply_gatekeeper\n",
        "policy = Policy(\n",
        "    version=\"1.0\",\n",
        "    global_masking=True,\n",
        "    rules=[\n",
        "        Rule(tag_pattern=\"stress_mpa\", action=\"mask_value\"),\n",
        "        Rule(tag_pattern=\"temperature_celsius\", action=\"mask_value\"),\n",
        "        Rule(tag_pattern=\"efficiency\", action=\"mask_value\"),\n",
        "        Rule(tag_pattern=\"lifespan_hours\", action=\"mask_value\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "config = load_config('config/default.yaml')\n",
        "sanitized_path, vault_path = apply_gatekeeper(Path('turbine_data.xml'), policy, config)\n",
        "\n",
        "print(\"=== COMPLETE PIPELINE ===\\n\")\n",
        "print(f\"Input: turbine_data.xml\")\n",
        "print(f\"Sanitized output: {sanitized_path}\")\n",
        "print(f\"Vault: {vault_path}\")\n",
        "\n",
        "print(\"\\n--- SANITIZED CONTENT ---\")\n",
        "print(sanitized_path.read_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6nywz2KFnm4"
      },
      "source": [
        "## Using with Real LLM APIs\n",
        "\n",
        "To use with a real LLM, you would:\n",
        "\n",
        "### Option 1: Claude Desktop (MCP)\n",
        "```python\n",
        "# Configure in Claude Desktop settings:\n",
        "{\n",
        "  \"mcpServers\": {\n",
        "    \"molt-shield\": {\n",
        "      \"command\": \"python\",\n",
        "      \"args\": [\"-m\", \"src.server\"]\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### Option 2: OpenAI API\n",
        "```python\n",
        "import openai\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"Analyze this sanitized data: {sanitized_xml}\"}\n",
        "    ]\n",
        ")\n",
        "# Then rehydrate the response using vault\n",
        "```\n",
        "\n",
        "### Option 3: Gemini API\n",
        "```python\n",
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "response = model.generate_content(f\"Analyze: {sanitized_xml}\")\n",
        "# Then rehydrate\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w22wNzvFnm4"
      },
      "source": [
        "## Summary\n",
        "\n",
        "The Molt-Shield workflow:\n",
        "\n",
        "```\n",
        "1. YOUR DATA → 2. SANITIZE → 3. LLM → 4. REHYDRATE → 5. ORIGINAL\n",
        "   (private)      (safe to share)   (analyzes)    (maps back)\n",
        "```\n",
        "\n",
        "This ensures your proprietary data never leaves your control in an identifiable form."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}